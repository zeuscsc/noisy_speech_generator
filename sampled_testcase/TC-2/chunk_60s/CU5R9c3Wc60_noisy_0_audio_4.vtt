WEBVTT

00:00:00.000 --> 00:00:06.080
these approaches is this. Now, let's say here the red points and the green points are the points that

00:00:06.080 --> 00:00:12.080
you have hyper parameter one and hyper parameter hyper two hyper parameter two. Now these points,

00:00:12.080 --> 00:00:17.920
these reds and these greens are the points that the model has already trained on. The whites are

00:00:17.920 --> 00:00:22.640
yet to be trained. Now we know that the models performing good in this region and it's not so

00:00:22.640 --> 00:00:28.720
good in this region. Now with this information, this information is not used both of in both of grid

00:00:28.720 --> 00:00:34.320
search as well as random search. But if this is the information given to you, what would be the value

00:00:34.320 --> 00:00:39.760
or what would be the value that you would try for your next iteration? We are more likely to try around

00:00:39.760 --> 00:00:44.000
this area, isn't it? Because this is green, this is doing well, right? Because this area is doing

00:00:44.000 --> 00:00:49.280
well, we will try and find out for this particular region for the best possible parameter combination.

00:00:49.280 --> 00:00:54.320
But we don't take that information account when into account when we are using grid search as well

00:00:54.320 --> 00:01:01.600
as random search. So this is exactly what Bayesian optimization is all about. It tries to make use
