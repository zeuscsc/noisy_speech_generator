WEBVTT

00:00:00.000 --> 00:00:04.720
are familiar with the concept of reinforcement learning, if you are familiar with reinforcement

00:00:05.520 --> 00:00:09.600
learning with the idea behind say multi-arm bandits and all this is quite similar to that

00:00:10.240 --> 00:00:16.320
where this acquisition function will have the opportunity to explore either explore or exploit.

00:00:16.320 --> 00:00:21.040
Exploit means what it means is basically we know that these regions are doing well. If we know that

00:00:21.040 --> 00:00:26.400
these regions are doing well, we will try to for the next iteration when it goes for an exploit option,

00:00:26.400 --> 00:00:30.960
it will try to choose data points around this region. Okay, so it will go for data points in this

00:00:30.960 --> 00:00:37.360
in this particular zone. That would be exploit. Explore would be it will try to find out or try to test out

00:00:37.360 --> 00:00:41.680
data points that is farther away right randomly to choose some other point somewhere in the board

00:00:41.680 --> 00:00:47.200
and we'll try to explore how the model score turns out to be for a different configuration. So that's

00:00:47.200 --> 00:00:52.880
what explore is. So to do this, there are various techniques such as the expected improvement method

00:00:52.880 --> 00:01:00.480
or the upper confidence bound method you can use to use as the acquisition function. So this will
