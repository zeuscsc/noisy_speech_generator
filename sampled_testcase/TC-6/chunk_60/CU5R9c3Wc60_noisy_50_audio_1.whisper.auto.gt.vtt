WEBVTT

00:00:55.640 --> 00:01:00.640
compare the Y hat against the actual Y from the validation data set. From that you compute the

00:01:00.640 --> 00:01:06.100
error, which is called the validation error, right? We want this error to be as low as possible. In

00:01:06.100 --> 00:01:12.340
order to achieve that, one of the techniques is we try to see how the model is performing. That is

00:01:12.340 --> 00:01:19.140
the error. Performance is lower the error, better the performances. Now we try to adjust various

00:01:19.140 --> 00:01:25.220
combinations of the hyper parameters of whichever ML model that we are dealing with. For example,

00:01:25.220 --> 00:01:29.840
if we are dealing with say a random forest algorithm, the hyper parameter could be something

00:01:29.840 --> 00:01:36.720
like the number of estimators and say the max depth, right? And could be other parameters also.

00:01:37.580 --> 00:01:43.780
Likewise, if you use say support vector missions, it could be what kernel you are using, what kernel

00:01:43.780 --> 00:01:49.640
you are using, what the value of the C parameters, things like that, right? So for a specific value

00:01:49.640 --> 00:01:55.280
of these hyper parameters, the error might be lowest. This is what hyper parameter tuning is

00:01:55.280 --> 00:02:00.560
all about. Now the process of hyper parameter tuning itself is done using the most common method is using
